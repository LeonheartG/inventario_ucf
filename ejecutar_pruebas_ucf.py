#!/usr/bin/env python3
"""
Script para ejecutar todas las pruebas del Sistema UCF
Basado en las especificaciones del documento de YaidelÃ­n Chaviano

Estrategia de pruebas implementada:
- Pruebas unitarias (mÃ³dulo inventario)
- Pruebas de integraciÃ³n (mÃ³dulo usuarios)
- Pruebas de aceptaciÃ³n (mÃ³dulo diagnÃ³stico)

Uso:
    python ejecutar_pruebas_ucf.py [opciones]
"""

import os
import sys
import django
from django.conf import settings
from django.test.utils import get_runner
from django.core.management import execute_from_command_line
import time
import subprocess
from io import StringIO
from contextlib import redirect_stdout, redirect_stderr


class TestRunner:
    """
    Ejecutor de pruebas del Sistema UCF
    Implementa la estrategia de pruebas del documento de YaidelÃ­n Chaviano
    """

    def __init__(self):
        self.setup_project_paths()
        self.setup_django()
        self.resultados = {
            'unitarias': {'total': 0, 'exitosas': 0, 'fallidas': 0, 'tiempo': 0},
            'integracion': {'total': 0, 'exitosas': 0, 'fallidas': 0, 'tiempo': 0},
            'aceptacion': {'total': 0, 'exitosas': 0, 'fallidas': 0, 'tiempo': 0}
        }

    def setup_project_paths(self):
        """Configurar paths del proyecto para ejecuciÃ³n sin entorno virtual"""
        # Obtener directorio actual (raÃ­z del proyecto)
        project_root = os.path.dirname(os.path.abspath(__file__))

        # Agregar raÃ­z del proyecto al Python path si no estÃ¡
        if project_root not in sys.path:
            sys.path.insert(0, project_root)

        # Cambiar al directorio del proyecto
        os.chdir(project_root)

        print(f"ğŸ“ Directorio de trabajo: {project_root}")

    def setup_django(self):
        """Configurar entorno Django para las pruebas"""
        try:
            os.environ.setdefault('DJANGO_SETTINGS_MODULE',
                                  'inventario_ucf.settings')
            django.setup()
        except Exception as e:
            print(f"âŒ Error configurando Django: {e}")
            print(
                "   Verifica que el archivo settings.py estÃ© en inventario_ucf/settings.py")
            sys.exit(1)

    def print_header(self, titulo):
        """Imprimir encabezado de secciÃ³n"""
        print("\n" + "="*80)
        print(f"   {titulo}")
        print("="*80)

    def print_subheader(self, subtitulo):
        """Imprimir subencabezado"""
        print(f"\n{'-'*60}")
        print(f"   {subtitulo}")
        print(f"{'-'*60}")

    def verificar_dependencias(self):
        """Verificar dependencias necesarias para las pruebas - Mejorado para sin entorno virtual"""
        self.print_subheader("VERIFICACIÃ“N DE DEPENDENCIAS")

        dependencias = [
            ('Django', 'django'),
            ('Pillow', 'PIL'),
            ('ReportLab', 'reportlab'),
            ('XlsxWriter', 'xlsxwriter'),
        ]

        dependencias_faltantes = []
        dependencias_instaladas = []

        for nombre, modulo in dependencias:
            try:
                # Intentar importar el mÃ³dulo
                imported_module = __import__(modulo)

                # Verificar si realmente se importÃ³ correctamente
                if hasattr(imported_module, '__version__'):
                    version = imported_module.__version__
                elif hasattr(imported_module, 'VERSION'):
                    version = str(imported_module.VERSION)
                elif hasattr(imported_module, 'version'):
                    version = str(imported_module.version)
                else:
                    version = "instalado"

                print(f"âœ… {nombre} - Instalado ({version})")
                dependencias_instaladas.append(nombre)

            except ImportError as e:
                print(f"âŒ {nombre} - NO INSTALADO")
                print(f"   Error: {str(e)}")
                dependencias_faltantes.append(nombre)
            except Exception as e:
                print(f"âš ï¸  {nombre} - ERROR AL VERIFICAR: {str(e)}")
                dependencias_faltantes.append(nombre)

        print(f"\nğŸ“Š Resumen de dependencias:")
        print(f"   âœ… Instaladas: {len(dependencias_instaladas)}")
        print(f"   âŒ Faltantes: {len(dependencias_faltantes)}")

        if dependencias_faltantes:
            print(
                f"\nâš ï¸  Dependencias faltantes: {', '.join(dependencias_faltantes)}")
            print("   Para instalar manualmente:")
            for dep in dependencias_faltantes:
                if dep == 'Pillow':
                    print("     pip install Pillow")
                elif dep == 'ReportLab':
                    print("     pip install reportlab")
                elif dep == 'XlsxWriter':
                    print("     pip install XlsxWriter")
                else:
                    print(f"     pip install {dep}")
            print("\n   O instalar todas desde requirements.txt:")
            print("     pip install -r requirements.txt")

            # Intentar autoinstalaciÃ³n
            respuesta = input(
                "\nÂ¿Deseas intentar instalar automÃ¡ticamente las dependencias faltantes? (s/n): ")
            if respuesta.lower() in ['s', 'si', 'sÃ­', 'y', 'yes']:
                self.autoinstalar_dependencias(dependencias_faltantes)
                return self.verificar_dependencias()  # Re-verificar despuÃ©s de la instalaciÃ³n
            else:
                return False
        else:
            print("\nâœ… Todas las dependencias estÃ¡n instaladas")
            return True

    def autoinstalar_dependencias(self, dependencias_faltantes):
        """Intentar instalar automÃ¡ticamente las dependencias faltantes"""
        print("\nğŸ”§ Intentando instalar dependencias automÃ¡ticamente...")

        # Mapeo de nombres de dependencias a nombres de paquetes pip
        pip_names = {
            'Pillow': 'Pillow',
            'ReportLab': 'reportlab',
            'XlsxWriter': 'XlsxWriter',
            'Django': 'Django'
        }

        for dep in dependencias_faltantes:
            if dep in pip_names:
                package_name = pip_names[dep]
                try:
                    print(f"   Instalando {package_name}...")
                    subprocess.check_call(
                        [sys.executable, '-m', 'pip', 'install', package_name])
                    print(f"   âœ… {dep} instalado correctamente")
                except subprocess.CalledProcessError as e:
                    print(f"   âŒ Error instalando {dep}: {e}")
                except Exception as e:
                    print(f"   âŒ Error inesperado instalando {dep}: {e}")

    def ejecutar_pruebas_unitarias(self):
        """
        Ejecutar pruebas unitarias del mÃ³dulo inventario
        SecciÃ³n 3.2.1: Pruebas unitarias para componentes individuales
        """
        self.print_subheader("PRUEBAS UNITARIAS - MÃ“DULO INVENTARIO")
        print("Validando lÃ³gica de negocio en componentes individuales...")

        start_time = time.time()

        try:
            # Configurar runner de pruebas
            TestRunner = get_runner(settings)
            test_runner = TestRunner(
                verbosity=2, interactive=False, keepdb=True)

            # Ejecutar pruebas unitarias del inventario
            failures = test_runner.run_tests(['inventario.test_unitarias'])

            end_time = time.time()
            self.resultados['unitarias']['tiempo'] = round(
                end_time - start_time, 2)

            if failures == 0:
                print("âœ… TODAS LAS PRUEBAS UNITARIAS PASARON")
                self.resultados['unitarias']['exitosas'] = 1
            else:
                print(f"âŒ {failures} PRUEBAS UNITARIAS FALLARON")
                self.resultados['unitarias']['fallidas'] = failures

        except Exception as e:
            print(f"âŒ ERROR EJECUTANDO PRUEBAS UNITARIAS: {str(e)}")
            self.resultados['unitarias']['fallidas'] = 1

        print(
            f"â±ï¸  Tiempo de ejecuciÃ³n: {self.resultados['unitarias']['tiempo']} segundos")

    def ejecutar_pruebas_integracion(self):
        """
        Ejecutar pruebas de integraciÃ³n del mÃ³dulo usuarios
        SecciÃ³n 3.2.2: Pruebas de interacciÃ³n entre componentes
        """
        self.print_subheader("PRUEBAS DE INTEGRACIÃ“N - MÃ“DULO USUARIOS")
        print("Validando interacciÃ³n entre componentes del sistema...")

        start_time = time.time()

        try:
            TestRunner = get_runner(settings)
            test_runner = TestRunner(
                verbosity=2, interactive=False, keepdb=True)

            # Ejecutar pruebas de integraciÃ³n
            failures = test_runner.run_tests(['usuarios.test_integracion'])

            end_time = time.time()
            self.resultados['integracion']['tiempo'] = round(
                end_time - start_time, 2)

            if failures == 0:
                print("âœ… TODAS LAS PRUEBAS DE INTEGRACIÃ“N PASARON")
                self.resultados['integracion']['exitosas'] = 1
            else:
                print(f"âŒ {failures} PRUEBAS DE INTEGRACIÃ“N FALLARON")
                self.resultados['integracion']['fallidas'] = failures

        except Exception as e:
            print(f"âŒ ERROR EJECUTANDO PRUEBAS DE INTEGRACIÃ“N: {str(e)}")
            self.resultados['integracion']['fallidas'] = 1

        print(
            f"â±ï¸  Tiempo de ejecuciÃ³n: {self.resultados['integracion']['tiempo']} segundos")

    def ejecutar_pruebas_aceptacion(self):
        """
        Ejecutar pruebas de aceptaciÃ³n del mÃ³dulo diagnÃ³stico
        SecciÃ³n 3.2.3: Pruebas de usabilidad y satisfacciÃ³n de requisitos
        """
        self.print_subheader("PRUEBAS DE ACEPTACIÃ“N - MÃ“DULO DIAGNÃ“STICO")
        print("Validando usabilidad y satisfacciÃ³n de requisitos...")

        start_time = time.time()

        try:
            TestRunner = get_runner(settings)
            test_runner = TestRunner(
                verbosity=2, interactive=False, keepdb=True)

            # Ejecutar pruebas de aceptaciÃ³n
            failures = test_runner.run_tests(['diagnostico.test_aceptacion'])

            end_time = time.time()
            self.resultados['aceptacion']['tiempo'] = round(
                end_time - start_time, 2)

            if failures == 0:
                print("âœ… TODAS LAS PRUEBAS DE ACEPTACIÃ“N PASARON")
                self.resultados['aceptacion']['exitosas'] = 1
            else:
                print(f"âŒ {failures} PRUEBAS DE ACEPTACIÃ“N FALLARON")
                self.resultados['aceptacion']['fallidas'] = failures

        except Exception as e:
            print(f"âŒ ERROR EJECUTANDO PRUEBAS DE ACEPTACIÃ“N: {str(e)}")
            self.resultados['aceptacion']['fallidas'] = 1

        print(
            f"â±ï¸  Tiempo de ejecuciÃ³n: {self.resultados['aceptacion']['tiempo']} segundos")

    def verificar_cobertura_codigo(self):
        """
        Verificar cobertura de cÃ³digo (si coverage estÃ¡ instalado)
        Objetivo: >80% segÃºn buenas prÃ¡cticas
        """
        self.print_subheader("ANÃLISIS DE COBERTURA DE CÃ“DIGO")

        try:
            # Verificar si coverage estÃ¡ instalado
            subprocess.run([sys.executable, '-m', 'coverage', '--version'],
                           capture_output=True, check=True)

            print("ğŸ“Š Generando reporte de cobertura...")

            # Ejecutar pruebas con coverage
            subprocess.run([
                sys.executable, '-m', 'coverage', 'run', '--source=.',
                'manage.py', 'test',
                'inventario.test_unitarias',
                'usuarios.test_integracion',
                'diagnostico.test_aceptacion'
            ], check=True)

            # Generar reporte
            result = subprocess.run([sys.executable, '-m', 'coverage', 'report'],
                                    capture_output=True, text=True)

            print("ğŸ“ˆ Reporte de Cobertura:")
            print(result.stdout)

            # Generar reporte HTML
            subprocess.run(
                [sys.executable, '-m', 'coverage', 'html'], check=True)
            print("ğŸ“Š Reporte HTML generado en htmlcov/index.html")

        except subprocess.CalledProcessError:
            print("âš ï¸  Coverage no estÃ¡ instalado o fallÃ³")
            print("   Instalar con: pip install coverage")
        except FileNotFoundError:
            print("âš ï¸  Coverage no encontrado")

    def generar_reporte_resultados(self):
        """Generar reporte final de resultados"""
        self.print_header("REPORTE FINAL DE PRUEBAS")

        # Calcular totales
        total_exitosas = sum(r['exitosas'] for r in self.resultados.values())
        total_fallidas = sum(r['fallidas'] for r in self.resultados.values())
        tiempo_total = sum(r['tiempo'] for r in self.resultados.values())

        print(f"""
ğŸ“‹ RESUMEN EJECUTIVO:
   â€¢ Pruebas exitosas: {total_exitosas}/3 mÃ³dulos
   â€¢ Pruebas fallidas:  {total_fallidas}
   â€¢ Tiempo total:      {tiempo_total:.2f} segundos

ğŸ“Š DETALLE POR TIPO DE PRUEBA:
""")

        tipos_prueba = {
            'unitarias': 'Pruebas Unitarias (Inventario)',
            'integracion': 'Pruebas de IntegraciÃ³n (Usuarios)',
            'aceptacion': 'Pruebas de AceptaciÃ³n (DiagnÃ³stico)'
        }

        for tipo, nombre in tipos_prueba.items():
            resultado = self.resultados[tipo]
            estado = "âœ… Ã‰XITO" if resultado['exitosas'] > 0 else "âŒ FALLÃ“"
            print(f"   â€¢ {nombre}: {estado} ({resultado['tiempo']:.2f}s)")

        # Indicadores de calidad segÃºn el documento
        print(f"""
ğŸ¯ INDICADORES DE CALIDAD:
   â€¢ ReducciÃ³n de errores: {"âœ… Logrado" if total_fallidas == 0 else "âŒ Pendiente"}
   â€¢ Tiempo de respuesta:  {"âœ… <3s por mÃ³dulo" if all(r['tiempo'] < 3 for r in self.resultados.values()) else "âš ï¸  Revisar"}
   â€¢ Cobertura de cÃ³digo:  {"ğŸ“Š Ver reporte coverage" if self.verificar_coverage_disponible() else "âš ï¸  No medido"}

ğŸ† NIVEL DE CALIDAD ALCANZADO:
""")

        if total_fallidas == 0:
            print("   ğŸ¥‡ EXCELENTE - Todas las pruebas pasaron")
            print("   âœ… Sistema listo para producciÃ³n")
        elif total_fallidas <= 2:
            print("   ğŸ¥ˆ BUENO - Algunas pruebas requieren atenciÃ³n")
            print("   âš ï¸  Revisar fallos antes de despliegue")
        else:
            print("   ğŸ¥‰ MEJORABLE - MÃºltiples fallos detectados")
            print("   âŒ Requiere correcciones antes de continuar")

    def verificar_coverage_disponible(self):
        """Verificar si coverage estÃ¡ disponible"""
        try:
            subprocess.run([sys.executable, '-m', 'coverage', '--version'],
                           capture_output=True, check=True)
            return True
        except:
            return False

    def ejecutar_suite_completa(self):
        """Ejecutar suite completa de pruebas"""
        self.print_header("SISTEMA DE PRUEBAS UCF - YAIDELÃN CHAVIANO")
        print("Implementando estrategia de pruebas del documento de investigaciÃ³n")
        print("Universidad de Cienfuegos - Sistema de GestiÃ³n de Inventarios TecnolÃ³gicos")

        # Verificar dependencias
        if not self.verificar_dependencias():
            print("\nâŒ No se pueden ejecutar las pruebas sin las dependencias")
            return

        # Ejecutar cada tipo de prueba
        self.ejecutar_pruebas_unitarias()
        self.ejecutar_pruebas_integracion()
        self.ejecutar_pruebas_aceptacion()

        # Verificar cobertura si estÃ¡ disponible
        self.verificar_cobertura_codigo()

        # Generar reporte final
        self.generar_reporte_resultados()

    def ejecutar_por_tipo(self, tipo_prueba):
        """Ejecutar solo un tipo especÃ­fico de pruebas"""
        if tipo_prueba == 'unitarias':
            self.ejecutar_pruebas_unitarias()
        elif tipo_prueba == 'integracion':
            self.ejecutar_pruebas_integracion()
        elif tipo_prueba == 'aceptacion':
            self.ejecutar_pruebas_aceptacion()
        else:
            print(f"âŒ Tipo de prueba no vÃ¡lido: {tipo_prueba}")
            print("   Tipos vÃ¡lidos: unitarias, integracion, aceptacion")


def main():
    """FunciÃ³n principal del script"""
    import argparse

    parser = argparse.ArgumentParser(
        description='Ejecutor de pruebas del Sistema UCF',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:
  python ejecutar_pruebas_ucf.py                    # Ejecutar todas las pruebas
  python ejecutar_pruebas_ucf.py --tipo unitarias   # Solo pruebas unitarias
  python ejecutar_pruebas_ucf.py --tipo integracion # Solo pruebas de integraciÃ³n
  python ejecutar_pruebas_ucf.py --tipo aceptacion  # Solo pruebas de aceptaciÃ³n
  python ejecutar_pruebas_ucf.py --coverage         # Incluir anÃ¡lisis de cobertura
        """
    )

    parser.add_argument(
        '--tipo',
        choices=['unitarias', 'integracion', 'aceptacion'],
        help='Tipo especÃ­fico de pruebas a ejecutar'
    )

    parser.add_argument(
        '--coverage',
        action='store_true',
        help='Incluir anÃ¡lisis de cobertura de cÃ³digo'
    )

    parser.add_argument(
        '--verbose',
        action='store_true',
        help='Salida detallada'
    )

    args = parser.parse_args()

    # Crear runner
    runner = TestRunner()

    try:
        if args.tipo:
            # Ejecutar tipo especÃ­fico
            runner.ejecutar_por_tipo(args.tipo)
        else:
            # Ejecutar suite completa
            runner.ejecutar_suite_completa()

    except KeyboardInterrupt:
        print("\n\nâš ï¸  EjecuciÃ³n interrumpida por el usuario")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Error inesperado: {str(e)}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
